/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:35082'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:38185'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:41423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:36359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:41648'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:33521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:38150'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:38861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:41569'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:35956'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:41459'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:36251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:38396'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:43942'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:39130'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:43450'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:41526'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:32806'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:40955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:41468'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:41241'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:36791'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:42459'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:38663'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:43858'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:33029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:42788'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.175:44407'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:33665
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:40613
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:35840
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:33665
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:40613
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:45890
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:35840
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:45890
distributed.worker - INFO -              nanny at:         172.30.6.175:42788
distributed.worker - INFO -              nanny at:         172.30.6.175:43450
distributed.worker - INFO -              nanny at:         172.30.6.175:41526
distributed.worker - INFO -              nanny at:         172.30.6.175:44407
distributed.worker - INFO -              bokeh at:         172.30.6.175:33933
distributed.worker - INFO -              bokeh at:         172.30.6.175:35165
distributed.worker - INFO -              bokeh at:         172.30.6.175:41693
distributed.worker - INFO -              bokeh at:         172.30.6.175:34220
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vmyx93oi
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_9akbecc
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tk6byp6f
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-u2mm0_v3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:35672
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:35672
distributed.worker - INFO -              nanny at:         172.30.6.175:41569
distributed.worker - INFO -              bokeh at:         172.30.6.175:45353
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-n7lzyh0a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:37104
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:37104
distributed.worker - INFO -              nanny at:         172.30.6.175:38150
distributed.worker - INFO -              bokeh at:         172.30.6.175:46492
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ah7_k46i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:45063
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:45063
distributed.worker - INFO -              nanny at:         172.30.6.175:41423
distributed.worker - INFO -              bokeh at:         172.30.6.175:45546
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ow43z5eu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:36821
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:46663
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:46663
distributed.worker - INFO -              nanny at:         172.30.6.175:38663
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:36821
distributed.worker - INFO -              nanny at:         172.30.6.175:41468
distributed.worker - INFO -              bokeh at:         172.30.6.175:45657
distributed.worker - INFO -              bokeh at:         172.30.6.175:36361
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-b__842en
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1im_pj3v
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:33787
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:33787
distributed.worker - INFO -              nanny at:         172.30.6.175:33521
distributed.worker - INFO -              bokeh at:         172.30.6.175:36395
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j7e_zcqv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:42551
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:42551
distributed.worker - INFO -              nanny at:         172.30.6.175:32806
distributed.worker - INFO -              bokeh at:         172.30.6.175:35451
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-07zdbrss
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:43418
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:43418
distributed.core - INFO - Starting established connection
distributed.worker - INFO -              nanny at:         172.30.6.175:39130
distributed.worker - INFO -              bokeh at:         172.30.6.175:42473
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wtmv_t66
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:40642
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:40642
distributed.worker - INFO -              nanny at:         172.30.6.175:35082
distributed.worker - INFO -              bokeh at:         172.30.6.175:45937
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-q7z0el2r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:33699
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:33699
distributed.worker - INFO -              nanny at:         172.30.6.175:38185
distributed.worker - INFO -              bokeh at:         172.30.6.175:44888
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wf8tldlk
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:41383
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:41383
distributed.worker - INFO -              nanny at:         172.30.6.175:43858
distributed.worker - INFO -              bokeh at:         172.30.6.175:42619
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_vm75nlo
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:44804
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:44804
distributed.worker - INFO -              nanny at:         172.30.6.175:36359
distributed.worker - INFO -              bokeh at:         172.30.6.175:35789
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e1swwhdp
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:44860
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:44860
distributed.worker - INFO -              nanny at:         172.30.6.175:35956
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO -              bokeh at:         172.30.6.175:38482
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.core - INFO - Starting established connection
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6i8p8m42
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:38299
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:38299
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              nanny at:         172.30.6.175:38861
distributed.core - INFO - Starting established connection
distributed.worker - INFO -              bokeh at:         172.30.6.175:41317
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ytq8750a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:44474
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:44474
distributed.worker - INFO -              nanny at:         172.30.6.175:33029
distributed.worker - INFO -              bokeh at:         172.30.6.175:42474
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zjw1d_vp
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:40935
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:40935
distributed.worker - INFO -              nanny at:         172.30.6.175:42459
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO -              bokeh at:         172.30.6.175:42059
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.core - INFO - Starting established connection
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gi4kraur
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:35083
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:35083
distributed.worker - INFO -              nanny at:         172.30.6.175:36251
distributed.worker - INFO -              bokeh at:         172.30.6.175:41536
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uuhnvkkz
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:35405
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:35405
distributed.worker - INFO -              nanny at:         172.30.6.175:36791
distributed.worker - INFO -              bokeh at:         172.30.6.175:37974
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-orpb79sx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:34213
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:34213
distributed.worker - INFO -              nanny at:         172.30.6.175:41459
distributed.worker - INFO -              bokeh at:         172.30.6.175:46235
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-768h90er
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:46489
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:46489
distributed.worker - INFO -              nanny at:         172.30.6.175:41241
distributed.worker - INFO -              bokeh at:         172.30.6.175:42292
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wa8qakow
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:41480
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:41480
distributed.worker - INFO -              nanny at:         172.30.6.175:41648
distributed.worker - INFO -              bokeh at:         172.30.6.175:40021
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-78d1xjqi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:45902
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:45902
distributed.worker - INFO -              nanny at:         172.30.6.175:43942
distributed.worker - INFO -              bokeh at:         172.30.6.175:39252
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1blp0fyf
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:37501
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:37501
distributed.worker - INFO -              nanny at:         172.30.6.175:38396
distributed.worker - INFO -              bokeh at:         172.30.6.175:45876
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ni2abkgs
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.175:40882
distributed.worker - INFO -          Listening to:   tcp://172.30.6.175:40882
distributed.worker - INFO -              nanny at:         172.30.6.175:40955
distributed.core - INFO - Starting established connection
distributed.worker - INFO -              bokeh at:         172.30.6.175:42602
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6nfoa366
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:46204
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 157.99 MB from 2051 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 157.96 MB from 275 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 39.40 MB from 965 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 20.58 MB from 2178 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.utils_perf - INFO - full garbage collection released 158.01 MB from 4276 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:46204
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:38299
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:37501
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:41383
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:46489
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:33699
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:44860
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:44474
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:34213
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:38861'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:41480
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:35840
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:42551
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:38396'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:45890
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:33787
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:41241'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:43418
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:43858'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:33665
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:35956'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:45063
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:33029'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:46663
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:40613
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:35672
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:40882
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:41648'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:45902
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:40935
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:36821
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:42788'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:40642
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:41459'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:32806'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:38185'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:44804
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:44407'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:33521'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:39130'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:43450'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:41423'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:35083
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:35405
distributed.worker - INFO - Stopping worker at tcp://172.30.6.175:37104
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:38663'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:41526'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:40955'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:41569'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:41468'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:43942'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:35082'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:42459'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:36359'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:36251'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:36791'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.175:38150'
distributed.dask_worker - INFO - End worker
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
