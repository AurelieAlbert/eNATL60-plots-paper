/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:40331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:41708'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:42423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:37294'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:42857'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:41036'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:33169'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:36747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:33432'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:42160'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:36300'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:35867'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:39274'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:37567'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:44766'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:45187'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:36602'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:45908'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:39134'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:35031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:45946'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:37591'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:41711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:38263'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:33848'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:38509'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:34780'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.211:40221'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:34680
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:34680
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:44252
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:44252
distributed.worker - INFO -              nanny at:         172.30.8.211:35031
distributed.worker - INFO -              bokeh at:         172.30.8.211:37625
distributed.worker - INFO -              nanny at:         172.30.8.211:42160
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              bokeh at:         172.30.8.211:40387
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ufsmwywn
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j5ze9_kz
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:42510
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:42510
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:39817
distributed.worker - INFO -              nanny at:         172.30.8.211:45946
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:39817
distributed.worker - INFO -              nanny at:         172.30.8.211:33848
distributed.worker - INFO -              bokeh at:         172.30.8.211:34401
distributed.worker - INFO -              bokeh at:         172.30.8.211:42768
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sbd10wix
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2qvmiqt0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:44482
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:44482
distributed.worker - INFO -              nanny at:         172.30.8.211:36747
distributed.worker - INFO -              bokeh at:         172.30.8.211:38538
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wgoazpzl
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:40566
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:40566
distributed.worker - INFO -              nanny at:         172.30.8.211:45908
distributed.worker - INFO -              bokeh at:         172.30.8.211:34623
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5onc7vys
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:34245
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:34245
distributed.worker - INFO -              nanny at:         172.30.8.211:37591
distributed.worker - INFO -              bokeh at:         172.30.8.211:33740
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-02plo71e
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:45219
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:45219
distributed.worker - INFO -              nanny at:         172.30.8.211:41711
distributed.worker - INFO -              bokeh at:         172.30.8.211:41751
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1hjy11st
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:41113
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:41113
distributed.worker - INFO -              nanny at:         172.30.8.211:33432
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:45402
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:45402
distributed.worker - INFO -              nanny at:         172.30.8.211:42423
distributed.worker - INFO -              bokeh at:         172.30.8.211:37556
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tnm77v8g
distributed.worker - INFO -              bokeh at:         172.30.8.211:43832
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6ellfrp3
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:36935
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:36935
distributed.worker - INFO -              nanny at:         172.30.8.211:37567
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:38197
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:38197
distributed.worker - INFO -              bokeh at:         172.30.8.211:40098
distributed.worker - INFO -              nanny at:         172.30.8.211:44766
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO -              bokeh at:         172.30.8.211:43368
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m9z0q93s
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:35410
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:35410
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -              nanny at:         172.30.8.211:45187
distributed.worker - INFO -              bokeh at:         172.30.8.211:41962
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-u77kvryp
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tkg0ax6c
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:34980
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:34980
distributed.worker - INFO -              nanny at:         172.30.8.211:39274
distributed.worker - INFO -              bokeh at:         172.30.8.211:35817
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:44583
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:44583
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -              nanny at:         172.30.8.211:36300
distributed.worker - INFO -              bokeh at:         172.30.8.211:44715
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pevykpsf
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sfxq6gx8
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:44186
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:44186
distributed.worker - INFO -              nanny at:         172.30.8.211:42857
distributed.worker - INFO -              bokeh at:         172.30.8.211:46722
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vc6jr686
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:37462
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:37462
distributed.worker - INFO -              nanny at:         172.30.8.211:35867
distributed.worker - INFO -              bokeh at:         172.30.8.211:40875
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-53ods5xr
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:37484
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:37484
distributed.worker - INFO -              nanny at:         172.30.8.211:40221
distributed.worker - INFO -              bokeh at:         172.30.8.211:37859
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wj41i50i
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:41378
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:41378
distributed.worker - INFO -              nanny at:         172.30.8.211:40331
distributed.worker - INFO -              bokeh at:         172.30.8.211:37143
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7fvxvorp
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:44080
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:44080
distributed.worker - INFO -              nanny at:         172.30.8.211:36602
distributed.worker - INFO -              bokeh at:         172.30.8.211:33625
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0g0byck8
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:40971
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:40971
distributed.worker - INFO -              nanny at:         172.30.8.211:33169
distributed.worker - INFO -              bokeh at:         172.30.8.211:38019
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-s1776ksw
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:37229
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:37229
distributed.worker - INFO -              nanny at:         172.30.8.211:39134
distributed.worker - INFO -              bokeh at:         172.30.8.211:39826
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4mpqydnk
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:35497
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:35497
distributed.worker - INFO -              nanny at:         172.30.8.211:37294
distributed.worker - INFO -              bokeh at:         172.30.8.211:38178
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-f1gifl9z
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:37123
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:37123
distributed.worker - INFO -              nanny at:         172.30.8.211:41036
distributed.worker - INFO -              bokeh at:         172.30.8.211:34296
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wk1gk8_t
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:34643
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:34643
distributed.worker - INFO -              nanny at:         172.30.8.211:41708
distributed.worker - INFO -              bokeh at:         172.30.8.211:44553
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:40626
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:40626
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sc8cszpv
distributed.worker - INFO -              nanny at:         172.30.8.211:34780
distributed.worker - INFO -              bokeh at:         172.30.8.211:37439
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-q3ajob0h
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:42277
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:42277
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:33696
distributed.worker - INFO -              nanny at:         172.30.8.211:38509
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:33696
distributed.worker - INFO -              bokeh at:         172.30.8.211:43088
distributed.worker - INFO -              nanny at:         172.30.8.211:38263
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO -              bokeh at:         172.30.8.211:37349
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xgx1mn5n
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-k8_8w9iz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 228.23 MB from 440 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 110.58 MB from 305 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 110.41 MB from 2160 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 110.36 MB from 3557 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 62.85 MB from 2398 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 110.35 MB from 986 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 110.24 MB from 2031 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39500 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x2b23279e6160>>, <Future finished exception=OSError("Timed out trying to connect to 'tcp://172.30.100.1:41041' after 10 s: connect() didn't finish in time")>)
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 218, in connect
    quiet_exceptions=EnvironmentError,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 743, in _run_callback
    ret = callback()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 767, in _discard_future_result
    future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 748, in heartbeat
    address=self.contact_address, now=time(), metrics=self.get_metrics()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 736, in send_recv_from_rpc
    comm = yield self.pool.connect(self.addr)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 864, in connect
    connection_args=self.connection_args,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 230, in connect
    _raise(error)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 207, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://172.30.100.1:41041' after 10 s: connect() didn't finish in time
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39896 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39550 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39520 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39798 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40062 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40116 remote=tcp://172.30.100.1:41041>
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x2b23279e6160>>, <Future finished exception=OSError("Timed out trying to connect to 'tcp://172.30.100.1:41041' after 10 s: connect() didn't finish in time")>)
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 218, in connect
    quiet_exceptions=EnvironmentError,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 743, in _run_callback
    ret = callback()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 767, in _discard_future_result
    future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 748, in heartbeat
    address=self.contact_address, now=time(), metrics=self.get_metrics()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 736, in send_recv_from_rpc
    comm = yield self.pool.connect(self.addr)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 864, in connect
    connection_args=self.connection_args,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 230, in connect
    _raise(error)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 207, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://172.30.100.1:41041' after 10 s: connect() didn't finish in time
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40432 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39518 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40426 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40172 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39446 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40506 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39480 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39792 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40500 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40278 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40546 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40330 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40384 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39642 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39690 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39954 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39796 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40170 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39444 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40504 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39478 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40334 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39694 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39958 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40474 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39456 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40522 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40250 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39492 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40300 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40354 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39572 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39664 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39712 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39816 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39870 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39924 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39978 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40190 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40398 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40112 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40496 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39472 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40274 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40326 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39548 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40380 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39638 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39686 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39950 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 53.01 MB from 1134 reference cycles (threshold: 10.00 MB)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40434 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40186 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40470 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40216 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40516 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40244 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40296 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40348 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39810 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39918 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39972 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40438 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40472 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40220 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40520 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40248 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40298 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40352 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39616 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39662 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40416 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39710 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39814 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39868 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39922 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39976 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 797 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40096 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40446 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40196 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40484 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40224 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40532 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40260 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40310 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40364 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40422 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39827 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39934 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39988 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40182 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40466 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39454 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40514 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39488 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40292 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39526 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40346 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39568 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39612 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39658 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40410 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39706 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39808 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39862 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39916 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39970 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 109.96 MB from 2423 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40194 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40480 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40530 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40258 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40306 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40360 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39670 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40420 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39718 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39824 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39878 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39932 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39984 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40442 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 75.38 MB from 1796 reference cycles (threshold: 10.00 MB)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40400 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40114 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40454 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40208 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40498 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40276 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40328 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39640 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39898 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39952 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1520 reference cycles (threshold: 10.00 MB)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40200 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40486 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40536 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39502 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40314 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39540 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40368 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39582 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39628 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40386 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39676 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39830 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39884 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40212 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39804 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40178 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40464 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40512 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40240 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40288 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39702 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39966 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40192 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40478 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39460 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40526 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40252 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39496 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40302 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40356 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39576 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39622 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39666 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39716 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39818 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39874 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39928 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39982 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40440 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40482 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39462 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40528 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40256 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39498 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40308 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39536 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40362 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39578 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39624 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39672 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40418 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39720 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39822 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39876 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39930 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39986 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40444 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 101.29 MB from 608 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39522 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40430 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40176 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40462 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39450 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40510 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39484 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40286 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40340 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39606 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39700 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39748 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39802 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39856 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39964 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40126 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40452 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40494 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40232 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40272 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39506 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40322 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39544 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40376 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39588 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39634 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40394 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39682 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39838 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40544 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39892 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39946 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40614 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 35.82 MB from 1585 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40180 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40214 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40290 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40344 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39704 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40476 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39458 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40524 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40254 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39494 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40304 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40358 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39574 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39668 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39714 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39820 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39872 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39926 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39980 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40448 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40204 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40490 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40228 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40316 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40372 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40388 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39832 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40540 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39886 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39940 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40202 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40488 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40230 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40318 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40370 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39630 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40390 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39678 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39834 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40538 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39888 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39942 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40198 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40534 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40262 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40312 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39538 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40366 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39722 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39828 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39936 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39990 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40492 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39468 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40270 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39504 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40320 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39542 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40374 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39586 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39632 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40392 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39680 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39836 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40542 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39890 remote=tcp://172.30.100.1:41041>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40404 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40118 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40424 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40168 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40502 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40238 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39476 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40280 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39514 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40332 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39554 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39598 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39692 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40456 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39794 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39902 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39956 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40612 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40630 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 110.47 MB from 2180 reference cycles (threshold: 10.00 MB)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40174 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39448 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40508 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39482 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40284 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40338 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39560 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39604 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40408 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39698 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40460 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39800 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39962 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40634 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 110.40 MB from 1718 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.53 MB from 957 reference cycles (threshold: 10.00 MB)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40436 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40184 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40468 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40218 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40518 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40246 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39490 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40294 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39528 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40350 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39570 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39614 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39660 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39708 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39812 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39866 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39920 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39974 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40282 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40336 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39558 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39602 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40406 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39696 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40458 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39960 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40632 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 110.42 MB from 2516 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:40396 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39684 remote=tcp://172.30.100.1:41041>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.211:39948 remote=tcp://172.30.100.1:41041>
distributed.utils_perf - INFO - full garbage collection released 121.03 MB from 1289 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 528 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 442 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 715 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 2723 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 712 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 960 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 818 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 975 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.61 MB from 1614 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1490 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.35 MB from 1479 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 61.39 MB from 1008 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 15.08 MB from 588 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 958 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 163.82 MB from 1145 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1160 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 705 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1099 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 163.82 MB from 913 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 536 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 215.56 MB from 449 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 37.65 MB from 328 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.62 MB from 625 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 62.55 MB from 568 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 44.70 MB from 2416 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.44 MB from 1075 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.37 MB from 1015 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 518 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 84.26 MB from 1372 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 111.44 MB from 1252 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 55.87 MB from 1153 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 634 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1542 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 666 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.30 MB from 149 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 44.44 MB from 700 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 77.61 MB from 822 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 216 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 2260 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 2867 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 411 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 396 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.nanny - WARNING - Worker process 58531 was killed by signal 15
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.47 MB from 1911 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 582 reference cycles (threshold: 10.00 MB)
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.203:39190
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 194, in read
    n_frames = yield stream.read_bytes(8)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2975, in get_data_from_worker
    max_connections=max_connections,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 533, in send_recv
    response = yield comm.read(deserializers=deserializers)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 141, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 12, 3, 0)
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 51, 3, 0) 0 .  Asking scheduler
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.203:39190
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 194, in read
    n_frames = yield stream.read_bytes(8)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2975, in get_data_from_worker
    max_connections=max_connections,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 533, in send_recv
    response = yield comm.read(deserializers=deserializers)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 139, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 769 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 2746 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.58 MB from 1008 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1271 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 2008 reference cycles (threshold: 10.00 MB)
distributed.nanny - WARNING - Restarting worker
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 78.10 MB from 3487 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.09 MB from 490 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 77.63 MB from 436 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 171.48 MB from 1345 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 618 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 646 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1550 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.9.69:41961
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 194, in read
    n_frames = yield stream.read_bytes(8)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2975, in get_data_from_worker
    max_connections=max_connections,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 533, in send_recv
    response = yield comm.read(deserializers=deserializers)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 141, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 111, 9, 1)
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 109, 14, 15) 0 .  Asking scheduler
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 444, 9, 1) 0 .  Asking scheduler
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 27, 14, 15)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1334 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 125.71 MB from 2531 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.9.69:41961
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 194, in read
    n_frames = yield stream.read_bytes(8)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2975, in get_data_from_worker
    max_connections=max_connections,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 533, in send_recv
    response = yield comm.read(deserializers=deserializers)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 141, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 109, 10, 8)
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 30, 10, 8)
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 69, 9, 1) 0 .  Asking scheduler
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 120, 10, 8) 0 .  Asking scheduler
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 439, 10, 8) 0 .  Asking scheduler
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 17, 9, 1)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 156.97 MB from 857 reference cycles (threshold: 10.00 MB)
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
distributed.nanny - WARNING - Worker process 58541 was killed by signal 15
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 917 reference cycles (threshold: 10.00 MB)
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.211:37462
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 194, in read
    n_frames = yield stream.read_bytes(8)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2975, in get_data_from_worker
    max_connections=max_connections,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 533, in send_recv
    response = yield comm.read(deserializers=deserializers)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 141, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 0, 9, 4)
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 0, 9, 4) 0 .  Asking scheduler
distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.32 MB from 586 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.9.69:41961
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 218, in connect
    quiet_exceptions=EnvironmentError,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2965, in get_data_from_worker
    comm = yield rpc.connect(worker)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 864, in connect
    connection_args=self.connection_args,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 230, in connect
    _raise(error)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 207, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://172.30.9.69:41961' after 10 s: in <distributed.comm.tcp.TCPConnector object at 0x2b2333109710>: ConnectionRefusedError: [Errno 111] Connection refused
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.211:37462
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 194, in read
    n_frames = yield stream.read_bytes(8)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2975, in get_data_from_worker
    max_connections=max_connections,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 533, in send_recv
    response = yield comm.read(deserializers=deserializers)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 141, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 42, 19, 1)
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 169, 19, 1) 0 .  Asking scheduler
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 42, 19, 1)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 669 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1068 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.211:37462
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 194, in read
    n_frames = yield stream.read_bytes(8)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2975, in get_data_from_worker
    max_connections=max_connections,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 533, in send_recv
    response = yield comm.read(deserializers=deserializers)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/tcp.py", line 141, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - INFO - Can't find dependencies for key ('moment_combine-partial-435de8bbfed89d2037ceebf8590c3b70', 89, 8, 1)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1028 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Dependent not found: ('moment_chunk-d1a699f269df0c16c4dd7d89d9d0dac8', 359, 8, 1) 0 .  Asking scheduler
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 96.59 MB from 1362 reference cycles (threshold: 10.00 MB)
distributed.nanny - WARNING - Restarting worker
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1226 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1466 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.37 MB from 2708 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:44973
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:44973
distributed.worker - INFO -              nanny at:         172.30.8.211:35867
distributed.worker - INFO -              bokeh at:         172.30.8.211:45177
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e2o4n0gr
distributed.worker - INFO - -------------------------------------------------
distributed.utils_perf - INFO - full garbage collection released 78.24 MB from 585 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 109.99 MB from 2302 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.34 MB from 1131 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.211:40052
distributed.worker - INFO -          Listening to:   tcp://172.30.8.211:40052
distributed.worker - INFO -              nanny at:         172.30.8.211:33169
distributed.worker - INFO -              bokeh at:         172.30.8.211:46067
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y9qrn4cv
distributed.worker - INFO - -------------------------------------------------
distributed.utils_perf - INFO - full garbage collection released 110.57 MB from 445 reference cycles (threshold: 10.00 MB)
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.211:37462
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 218, in connect
    quiet_exceptions=EnvironmentError,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2965, in get_data_from_worker
    comm = yield rpc.connect(worker)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 864, in connect
    connection_args=self.connection_args,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 230, in connect
    _raise(error)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 207, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://172.30.8.211:37462' after 10 s: in <distributed.comm.tcp.TCPConnector object at 0x2b234717c0f0>: ConnectionRefusedError: [Errno 111] Connection refused
distributed.utils_perf - INFO - full garbage collection released 44.42 MB from 346 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1507 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:41041
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 351 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1127 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 172.44 MB from 626 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 2080 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 377 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 1709 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 3201 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 2143 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 598 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
distributed.utils_perf - INFO - full garbage collection released 94.92 MB from 773 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 1672 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 355 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 519 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 558 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 689 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 521 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.33 MB from 2021 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/reductions.py:387: RuntimeWarning: invalid value encountered in true_divide
  u = total / n
distributed.utils_perf - INFO - full garbage collection released 110.60 MB from 596 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 70.71 MB from 3085 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 188.42 MB from 1460 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 110.43 MB from 1448 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 18.40 MB from 2761 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 221.03 MB from 1801 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:33696
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:34245
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:34643
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:34680
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:35410
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:34980
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:35497
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:36935
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:37123
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:37229
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:37484
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:38197
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:39817
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:40052
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:40566
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:40626
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:41113
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:42277
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:42510
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:41378
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:44080
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:44186
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:44252
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:44482
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:44973
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:44583
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:45219
distributed.worker - INFO - Stopping worker at tcp://172.30.8.211:45402
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:37591'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://172.30.100.1:41041' processes=196 cores=196>>
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/client.py", line 1055, in _heartbeat
    self.scheduler_comm.send({"op": "heartbeat-client"})
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/batched.py", line 119, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://172.30.100.1:41041' processes=196 cores=196>>
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/client.py", line 1055, in _heartbeat
    self.scheduler_comm.send({"op": "heartbeat-client"})
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/batched.py", line 119, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:40331'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:39274'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:35867'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:34780'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:41708'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:45908'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:39134'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:38263'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:36300'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:37294'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:42423'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:33432'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:45946'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:37567'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:42857'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:33848'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:40221'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:35031'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:42160'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:38509'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:33169'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:45187'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:44766'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:36747'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:41711'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:36602'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.211:41036'
distributed.dask_worker - INFO - End worker
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-17, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-29, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-16, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-4, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-21, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-15, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-23, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-6, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-20, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-27, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-14, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-9, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-26, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-3, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-8, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-13, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-11, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-5, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-25, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-19, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-10, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-2, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-18, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-24, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-28, started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(ForkServerProcess-1, started daemon)>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
slurmstepd: error: Exceeded step memory limit at some point.
slurmstepd: error: Exceeded job memory limit at some point.
